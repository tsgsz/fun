# -*- coding: utf-8 -*-

import re
import zlib
import logging

import scrapy
from .basic import BasicSpider

logger = logging.getLogger(__name__)

class LianjiaSpider(BasicSpider):
    name = 'lianjia.com'
    allow_domain = ['lianjia.com']    
    login_headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Encoding': 'gzip, deflate, sdch',
        'Accept-Language': 'zh-CN,zh;q=0.8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Content-Type': 'application/x-www-form-urlencoded',
        'Host': 'passport.lianjia.com',
        'Pragma': 'no-cache',
        'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'
    }
    
    def __init__(self, *args, **kwargs):
        super(eval(self.__class__.__name__), self).__init__(*args, **kwargs)
        self.city = getattr(self, 'city', 'bj')
        self.user = getattr(self, 'user', '18506571340')
        self.password = getattr(self, 'password', 'tsgsz19910406')
        self.district = list()
        self.auth_url = 'https://clogin.lianjia.com//authentication/authenticate"
        self.start_urls = [
            'https://{0}.lianjia.com/'.format(self.city)
        ]
    
    def parse(self, response):
        return self.pre_login(response)
        
    def pre_login(self, response):  
        return [scrapy.Request(url=self.auth_url, headers=self.login_headers, callback=self.login)]
        
    def login(self, response):
        
        #pattern = re.compile(r'JSESSIONID=(.*)')
        #jsessionid = pattern.findall(response.headers.getlist('Set-Cookie')[0])[0]
        
        gzipped = response.headers.get('Content-Encoding')
        html_content = response.text
        if gzipped:
            html_content = zlib.decompress(html_content, 16+zlib.MAX_WBITS)
            
        pattern = re.compile(r'value=\"(LT-.*)\"')
        lt = pattern.findall(html_content)[0]
        pattern = re.compile(r'name="execution" value="(.*)"')
        execution = pattern.findall(html_content)[0]
        
        login_form = {
            "service":"https://ajax.api.lianjia.com/login/login/getuserinfo",
            "mainAuthMethodName":"username-password",
            "accountSystem":"customer",
            "credential":{
                "username":self.user,
                "password":,
                "encodeVersion":"1"
            },
            "context":{},
            "loginTicketId":"xtenX2d6RfqGg2DydKZ5swOlY7Sg8mft",
            "version":"2.0",
            "ticketMaxAge":604800
        }
        login_form = {
            'acc'
            'username': self.user,
            'password': self.password,
            'execution': execution,
            '_eventId': 'submit',
            'lt': lt,
            'verifyCode': '',
            'redirect': '',
        }
        #meta={'cookiejar': response.meta['cookiejar']},
        print('hhhhhhhh')
        return [
            scrapy.FormRequest(
                url=self.auth_url, 
                formdata=login_form, 
                headers = self.login_headers,
                callback=self.after_login
            )
        ]
    
    def after_login(self, response):
        logger.error("#"*20)
        logger.error(response)
        logger.error("#"*20)
    
    